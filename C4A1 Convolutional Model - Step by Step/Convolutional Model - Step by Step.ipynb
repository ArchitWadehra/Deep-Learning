{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8407e9dc",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks: Step by Step\n",
    "\n",
    "implementing convolutional (CONV) and pooling (POOL) layers in numpy, including both forward propagation and backward propagation.\n",
    "\n",
    "**Notation**:\n",
    "- Superscript $[l]$ denotes an object of the $l^{th}$ layer. \n",
    "    - Example: $a^{[4]}$ is the $4^{th}$ layer activation. $W^{[5]}$ and $b^{[5]}$ are the $5^{th}$ layer parameters.\n",
    "\n",
    "\n",
    "- Superscript $(i)$ denotes an object from the $i^{th}$ example. \n",
    "    - Example: $x^{(i)}$ is the $i^{th}$ training example input.\n",
    "    \n",
    "    \n",
    "- Subscript $i$ denotes the $i^{th}$ entry of a vector.\n",
    "    - Example: $a^{[l]}_i$ denotes the $i^{th}$ entry of the activations in layer $l$, assuming this is a fully connected (FC) layer.\n",
    "    \n",
    "    \n",
    "- $n_H$, $n_W$ and $n_C$ denote respectively the height, width and number of channels of a given layer. If you want to reference a specific layer $l$, you can also write $n_H^{[l]}$, $n_W^{[l]}$, $n_C^{[l]}$. \n",
    "- $n_{H_{prev}}$, $n_{W_{prev}}$ and $n_{C_{prev}}$ denote respectively the height, width and number of channels of the previous layer. If referencing a specific layer $l$, this could also be denoted $n_H^{[l-1]}$, $n_W^{[l-1]}$, $n_C^{[l-1]}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c808342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from public_tests import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ea384f",
   "metadata": {},
   "source": [
    "#### Zero-Padding\n",
    "Zero-padding adds zeros around the border of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cffa41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    "    X_pad = np.pad(X, ((0,0), (pad,pad), (pad,pad), (0,0)), mode = 'constant', constant_values = (0,0))\n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9517f6e9",
   "metadata": {},
   "source": [
    "#### Single Step of Convolution\n",
    "apply the filter to a single position of the input which will be used to build a convolutional unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c865e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_single_step(a_slice_prev, W, b):\n",
    "    s = a_slice_prev * W\n",
    "    Z = np.sum(s)\n",
    "    Z = Z + float(b)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99558cf8",
   "metadata": {},
   "source": [
    "#### Forward Pass\n",
    "taking many filters and convolve them on the input. Each 'convolution' gives you a 2D matrix output which will then be stacked to get a 3D volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a5d12fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "    # Retrieve dimensions from A_prev's shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = np.shape(A_prev)\n",
    "    \n",
    "    # Retrieve dimensions from W's shape (≈1 line)\n",
    "    (f, f, n_C_prev, n_C) = np.shape(W)\n",
    "    \n",
    "    # Retrieve information from \"hparameters\" (≈2 lines)\n",
    "    stride = hparameters[\"stride\"]\n",
    "    pad = hparameters[\"pad\"]\n",
    "    \n",
    "    # Compute the dimensions of the CONV output volume using the formula given above. \n",
    "    n_H = int((n_H_prev - f + 2*pad)/stride) + 1\n",
    "    n_W = int((n_W_prev - f + 2*pad)/stride) + 1\n",
    "    \n",
    "    # Initialize the output volume Z with zeros. (≈1 line)\n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    # Create A_prev_pad by padding A_prev\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    \n",
    "    for i in range(m):                              # loop over the batch of training examples\n",
    "        a_prev_pad = A_prev_pad[i, :, :, :]         # Select ith training example's padded activation\n",
    "         \n",
    "        for h in range(n_H):                        # loop over vertical axis of the output volume\n",
    "            vert_start = stride*h\n",
    "            vert_end = stride*h + f\n",
    "            \n",
    "            for w in range(n_W):                    # loop over horizontal axis of the output volume\n",
    "                horiz_start = stride*w\n",
    "                horiz_end = stride*w + f\n",
    "                \n",
    "                for c in range(n_C):                # loop over channels (= #filters) of the output volume\n",
    "                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    \n",
    "                    weights = W[:, :, :, c]\n",
    "                    biases  = b[:, :, :, c]\n",
    "                    \n",
    "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, weights, biases)\n",
    "                    \n",
    "    # Save information in \"cache\" for the backprop\n",
    "    cache = (A_prev, W, b, hparameters)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892892cf",
   "metadata": {},
   "source": [
    "#### Pooling Layer\n",
    "The pooling (POOL) layer reduces the height and width of the input. It helps reduce computation, as well as helps make feature detectors more invariant to its position in the input. The two types of pooling layers are: \n",
    "\n",
    "- Max-pooling layer: slides an ($f, f$) window over the input and stores the max value of the window in the output.\n",
    "\n",
    "- Average-pooling layer: slides an ($f, f$) window over the input and stores the average value of the window in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26b7745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
    "    # Retrieve dimensions from the input shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve hyperparameters from \"hparameters\"\n",
    "    f = hparameters[\"f\"]\n",
    "    stride = hparameters[\"stride\"]\n",
    "    \n",
    "    # Define the dimensions of the output\n",
    "    n_H = int(1 + (n_H_prev - f) / stride)\n",
    "    n_W = int(1 + (n_W_prev - f) / stride)\n",
    "    n_C = n_C_prev\n",
    "    \n",
    "    # Initialize output matrix A\n",
    "    A = np.zeros((m, n_H, n_W, n_C))              \n",
    "\n",
    "    for i in range(m):                             # loop over the training examples\n",
    "        for h in range(n_H):                       # loop on the vertical axis of the output volume\n",
    "            vert_start = stride*h \n",
    "            vert_end = stride*h + f\n",
    "            \n",
    "            for w in range(n_W):                   # loop on the horizontal axis of the output volume\n",
    "                horiz_start = stride*w\n",
    "                horiz_end = stride*w + f\n",
    "                \n",
    "                for c in range(n_C):               # loop over the channels of the output volume\n",
    "                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                    \n",
    "                    if mode == 'max':\n",
    "                        A[i, h, w, c] = np.max(a_prev_slice)\n",
    "                    elif mode == 'average':\n",
    "                        A[i, h, w, c] = np.mean(a_prev_slice)\n",
    "                        \n",
    "    # Store the input and hparameters in \"cache\" for pool_backward()\n",
    "    cache = (A_prev, hparameters)\n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    # assert(A.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f9d0a4",
   "metadata": {},
   "source": [
    "#### Backward Pass\n",
    "\n",
    "$$dA \\mathrel{+}= \\sum _{h=0} ^{n_H} \\sum_{w=0} ^{n_W} W_c \\times dZ_{hw} $$\n",
    "\n",
    "$$dW_c  \\mathrel{+}= \\sum _{h=0} ^{n_H} \\sum_{w=0} ^ {n_W} a_{slice} \\times dZ_{hw}  $$\n",
    "\n",
    "$$db = \\sum_h \\sum_w dZ_{hw} $$\n",
    "\n",
    "- #### CONV Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2522b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_backward(dZ, cache):\n",
    "    # Retrieve information from \"cache\"\n",
    "    (A_prev, W, b, hparameters) = cache\n",
    "\n",
    "    # Retrieve dimensions from A_prev's shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "\n",
    "    # Retrieve dimensions from W's shape\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "\n",
    "    # Retrieve information from \"hparameters\"\n",
    "    stride = hparameters['stride']\n",
    "    pad = hparameters['pad']\n",
    "\n",
    "    # Retrieve dimensions from dZ's shape\n",
    "    (m, n_H, n_W, n_C) = dZ.shape\n",
    "\n",
    "    # Initialize dA_prev, dW, db with the correct shapes\n",
    "    dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev))                           \n",
    "    dW = np.zeros((f, f, n_C_prev, n_C))\n",
    "    db = np.zeros((1, 1, 1, n_C))\n",
    "\n",
    "    # Pad A_prev and dA_prev\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    dA_prev_pad = zero_pad(dA_prev, pad)\n",
    "\n",
    "    for i in range(m):  # loop over the training examples\n",
    "        # select ith training example from A_prev_pad and dA_prev_pad\n",
    "        a_prev_pad = A_prev_pad[i, :, :, :]\n",
    "        da_prev_pad = dA_prev_pad[i, :, :, :]\n",
    "\n",
    "        for h in range(n_H):            # loop over vertical axis of the output volume\n",
    "            for w in range(n_W):        # loop over horizontal axis of the output volume\n",
    "                for c in range(n_C):    # loop over the channels of the output volume\n",
    "\n",
    "                    # Find the corners of the current \"slice\"\n",
    "                    vert_start = stride * h\n",
    "                    vert_end = stride * h + f\n",
    "                    horiz_start = stride * w\n",
    "                    horiz_end = stride * w + f\n",
    "\n",
    "                    # Use the corners to define the slice from a_prev_pad\n",
    "                    a_slice = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "\n",
    "                    # Update gradients for the window and the filter's parameters using the code formulas given above\n",
    "                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:, :, :, c] * dZ[i, h, w, c]\n",
    "                    dW[:, :, :, c] += a_slice * dZ[i, h, w, c]\n",
    "                    db[:, :, :, c] += dZ[i, h, w, c]\n",
    "\n",
    "        # Set the ith training example's dA_prev to the unpaded da_prev_pad (Hint: use X[pad:-pad, pad:-pad, :])\n",
    "        dA_prev[i, :, :, :] = da_prev_pad[pad:-pad, pad:-pad, :]\n",
    "\n",
    "    # Making sure output shape is correct\n",
    "    assert (dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))\n",
    "\n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6f10ef",
   "metadata": {},
   "source": [
    "- #### Pooling Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d840381b",
   "metadata": {},
   "source": [
    "    - For Max Pooling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be98d37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_from_window(x):\n",
    "    mask = (x == np.max(x))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c21bc3c",
   "metadata": {},
   "source": [
    "    - for Average Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4c9e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_value(dz, shape):\n",
    "    (n_H, n_W) = shape\n",
    "    average = dz / (n_H * n_W)\n",
    "    a = np.ones(shape) * average\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d936c4",
   "metadata": {},
   "source": [
    "Putting it together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa163cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_backward(dA, cache, mode = \"max\"):\n",
    "    # Retrieve information from cache (≈1 line)  \n",
    "    (A_prev, hparameters) = cache\n",
    "    \n",
    "    # Retrieve hyperparameters from \"hparameters\" (≈2 lines)  \n",
    "    stride = hparameters['stride']\n",
    "    f = hparameters['f']\n",
    "    \n",
    "    # Retrieve dimensions from A_prev's shape and dA's shape (≈2 lines)\n",
    "    m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape\n",
    "    m, n_H, n_W, n_C = dA.shape\n",
    "    \n",
    "    # Initialize dA_prev with zeros (≈1 line)\n",
    "    dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev))\n",
    "    \n",
    "    for i in range(m):                           # loop over the training examples\n",
    "        a_prev = A_prev[i, :, :, :]\n",
    "        \n",
    "        for h in range(n_H):                     # loop on the vertical axis\n",
    "            for w in range(n_W):                 # loop on the horizontal axis\n",
    "                for c in range(n_C):             # loop over the channels (depth)\n",
    "                    vert_start  = stride*h\n",
    "                    vert_end    = vert_start + f\n",
    "                    horiz_start = stride*w\n",
    "                    horiz_end   = horiz_start + f\n",
    "                    \n",
    "                    if mode == 'max':\n",
    "                        # Use the corners and \"c\" to define the current slice from a_prev\n",
    "                        a_prev_slice = a_prev[vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                        # Create the mask from a_prev_slice\n",
    "                        mask = create_mask_from_window(a_prev_slice)\n",
    "                        # increase dA_prev by mask multiplied by the correct entry of dA\n",
    "                        dA_prev[i, vert_start:vert_end, horiz_start:horiz_end, c] += np.multiply(mask, dA[i, h, w, c])\n",
    "                    \n",
    "                    elif mode == 'average':\n",
    "                        # Get the value da from dA\n",
    "                        da = dA[i, h, w, c]\n",
    "                        # Define the shape of the filter as fxf\n",
    "                        shape = (f, f)\n",
    "                        # Distribute it to get the correct slice of dA_prev\n",
    "                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += distribute_value(da, shape)\n",
    "                          \n",
    "    # Making sure your output shape is correct\n",
    "    assert(dA_prev.shape == A_prev.shape)\n",
    "    \n",
    "    return dA_prev"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
